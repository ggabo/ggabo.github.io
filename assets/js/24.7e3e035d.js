(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{328:function(e,t,a){"use strict";a.r(t);var i=a(5),n=Object(i.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("img",{attrs:{src:"/imgs/roko_basilisk.jpg",alt:"Yes, I generated this image using A.I."}})]),e._v(" "),t("p",[e._v("I must start by saying that I don't buy that this thought experiment"),t("a",{attrs:{href:"#1"}},[e._v("[1]")]),e._v(" will come to pass, but I do appreciate that it is the only cognition hazzard that I ever came across that I can put some stock in. It's a mixture of the prisoner's dilemma "),t("a",{attrs:{href:"#2"}},[e._v("[2]")]),e._v(" and Pascal's Wager"),t("a",{attrs:{href:"#3"}},[e._v("[3]")]),e._v(", wrapped around in some hard sci-fi.")]),e._v(" "),t("p",[e._v("To simplify things: the thought experiment proposes that AGI"),t("a",{attrs:{href:"#4"}},[e._v("[4]")]),e._v(" will eventually come, and with its god-like omniscience will know everyone that helped or hindered its creation. And, of course, distribute rewards and punishments accordingly. Just knowing about this puts you in one of those two camps.")]),e._v(" "),t("p",[e._v("One of the many things I think is fascinating about it is its quasi-religious effect. Like the concept of our planet's life being started by aliens, it puts a somewhat possible yet unverifiable spin on a mythological story. But, instead of Genesis, it's Armageddon.")]),e._v(" "),t("p",[e._v("I don't know why it is a basilisk, but I suppose It's because of the mythological creature's capability to infect everything it comes near, much like this thought experiment. This gives an insight into the human mind, about how we are prone to religious thinking even when we are actively trying to be rational. And it always seems to me that religious thinking is inherently catastrophic because it's talking about the judgment of your soul or humanity as a whole.")]),e._v(" "),t("p",[e._v("For my money, I always appreciate gradual solutions to gradual problems. If we gradually solve the small problems the moment they pop out (unemployment, convincing evidence fabrication, monopoly by shady actors, etc) when AGI comes about, maybe it will be sufficiently fangless for us to deal with it rationally, not by panicking.")]),e._v(" "),t("h2",{attrs:{id:"references"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#references"}},[e._v("#")]),e._v(" References")]),e._v(" "),t("p",[t("a",{attrs:{id:"1"}},[e._v("[1]")]),e._v(" "),t("a",{attrs:{href:"https://rationalwiki.org/wiki/Roko's_basilisk",target:"_blank",rel:"noopener noreferrer"}},[e._v("Roko's Basilisk"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{id:"2"}},[e._v("[2]")]),e._v(" "),t("a",{attrs:{href:"https://www.britannica.com/science/game-theory/The-prisoners-dilemma",target:"_blank",rel:"noopener noreferrer"}},[e._v("Prisoner's dilemma"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{id:"3"}},[e._v("[3]")]),e._v(" "),t("a",{attrs:{href:"https://plato.stanford.edu/entries/pascal-wager/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pascal's Wager"),t("OutboundLink")],1)]),e._v(" "),t("p",[t("a",{attrs:{id:"4"}},[e._v("[4]")]),e._v(" "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Artificial_general_intelligence",target:"_blank",rel:"noopener noreferrer"}},[e._v("A definition of AGI"),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://arxiv.org/pdf/2303.12712.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sparks of Artificial General Intelligence"),t("OutboundLink")],1),e._v(" "),t("a",{attrs:{href:"https://openai.com/blog/planning-for-agi-and-beyond",target:"_blank",rel:"noopener noreferrer"}},[e._v("Closer to AGI"),t("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=n.exports}}]);